{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e96f8a0",
   "metadata": {},
   "source": [
    "1、Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dba5126",
   "metadata": {},
   "source": [
    "对传入的图片进行大小、像素等的变换，使之满足神经网络的输入要求。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a0ec4a",
   "metadata": {},
   "source": [
    "target_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8650e213",
   "metadata": {},
   "source": [
    "对标签类型进行变换，后处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eceb15",
   "metadata": {},
   "source": [
    "*以上都需要在DataSet中去定义好，通过get_item去得到变换后的、正确的、符合模型规范的特征和标签。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c68c68",
   "metadata": {},
   "source": [
    "2、torch.nn提供了我们构建神经网络所需要的所有模块，都是nn.Module的子类。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07055e19",
   "metadata": {},
   "source": [
    "3、如何去构建一个分类模型（基于手写字识别）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1e27aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1、导入一些基本的库\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b68dc01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "#2、确定在什么设备上训练模型\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\" #判断cuda是否可用\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4c3acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3、定义分类模型网络   12分钟时\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork,self).__init__()\n",
    "        self.flatten=nn.Flatten()\n",
    "        self.liner_relu_stack=nn.Sequential(\n",
    "            nn.Linear(28*28, 512),  #第0层，线性层/MLP/前馈神经网络，两个参数分别表示输入特征的特殊维度，输出的隐含层的大小\n",
    "            nn.ReLU(),              #非线性激活函数\n",
    "            nn.Linear(512, 512),    #第2层，##为什么要用这么多Liner和ReLU  分三层\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),     #第4层，logits，维度为10\n",
    "        )\n",
    "    def forward(self, x):   #代表模块的前向运算\n",
    "        x=self.flatten(x)\n",
    "        logits=self.flatten(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c09e3074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (liner_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#4、实例化model\n",
    "model=NeuralNetwork().to(device)  \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3d23f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class:tensor([34], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#5、使用model\n",
    "X=torch.rand(1, 28, 28, device=device)\n",
    "logits=model(X)\n",
    "pred_probab=nn.Softmax(dim=1)(logits) #预测的概率\n",
    "y_pred=pred_probab.argmax(1) #对概率求出最大值，得到样本的分类值\n",
    "print(f\"Predicted class:{y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aadd57f",
   "metadata": {},
   "source": [
    "4、该模型的层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70b59d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#1、看一下输入张量的大小\n",
    "input_image=torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f338225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "#2、查看Flatten的效果\n",
    "flatten=nn.Flatten() #从第一维到最后一维浓缩成一个维度\n",
    "flat_image=flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45ca5976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "#3、nn.Linear\n",
    "layer1=nn.Linear(in_features=28*28 ,out_features=20)\n",
    "hidden1=layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b595278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[ 0.3758,  0.2062, -0.1051,  0.3165,  0.3148,  0.0767,  0.2469,  0.5818,\n",
      "         -0.4367, -0.3949, -0.3052,  0.0841, -0.0545, -0.0668,  0.2776,  0.9790,\n",
      "          0.5659, -0.4810, -0.1284, -0.3587],\n",
      "        [ 0.2905,  0.1356, -0.1982,  0.2233,  0.4671,  0.0014,  0.4075,  0.0942,\n",
      "         -0.1422, -0.4951,  0.0769, -0.0526,  0.4538, -0.0665, -0.1765,  0.4787,\n",
      "          0.3414, -0.2654, -0.1421,  0.1242],\n",
      "        [ 0.3523,  0.2653, -0.4260,  0.1836,  0.3698,  0.2172,  0.1737,  0.2413,\n",
      "         -0.3954, -0.2000,  0.4418,  0.0600,  0.0892, -0.0521,  0.1705,  1.0458,\n",
      "          0.0155, -0.2811, -0.1302, -0.0715]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.3758, 0.2062, 0.0000, 0.3165, 0.3148, 0.0767, 0.2469, 0.5818, 0.0000,\n",
      "         0.0000, 0.0000, 0.0841, 0.0000, 0.0000, 0.2776, 0.9790, 0.5659, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2905, 0.1356, 0.0000, 0.2233, 0.4671, 0.0014, 0.4075, 0.0942, 0.0000,\n",
      "         0.0000, 0.0769, 0.0000, 0.4538, 0.0000, 0.0000, 0.4787, 0.3414, 0.0000,\n",
      "         0.0000, 0.1242],\n",
      "        [0.3523, 0.2653, 0.0000, 0.1836, 0.3698, 0.2172, 0.1737, 0.2413, 0.0000,\n",
      "         0.0000, 0.4418, 0.0600, 0.0892, 0.0000, 0.1705, 1.0458, 0.0155, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#4、非线性层nn.ReLU\n",
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1=nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bcb6957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5、nn.Sequential  #模块有序的容器\n",
    "seq_modules=nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image=torch.rand(3,28,28)\n",
    "logits=seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c0038d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6、nn.Softmax\n",
    "softmax=nn.Softmax(dim=1)\n",
    "pred_probab=softmax(logits) #关于10个类的分类后的概率分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25233b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (liner_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: liner_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values: tensor([[-0.0219,  0.0222, -0.0201,  ..., -0.0052,  0.0288, -0.0349],\n",
      "        [ 0.0306,  0.0259,  0.0101,  ..., -0.0106, -0.0114,  0.0074]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "\n",
      "Layer: liner_relu_stack.0.bias | Size: torch.Size([512]) | Values: tensor([-0.0325, -0.0255], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "\n",
      "Layer: liner_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values: tensor([[-0.0430,  0.0202,  0.0166,  ...,  0.0061,  0.0030, -0.0060],\n",
      "        [ 0.0317, -0.0050,  0.0259,  ..., -0.0275, -0.0270, -0.0076]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "\n",
      "Layer: liner_relu_stack.2.bias | Size: torch.Size([512]) | Values: tensor([0.0385, 0.0024], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "\n",
      "Layer: liner_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values: tensor([[ 0.0217, -0.0265, -0.0364,  ..., -0.0271,  0.0434,  0.0208],\n",
      "        [-0.0178,  0.0042,  0.0206,  ..., -0.0429, -0.0438,  0.0240]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "\n",
      "Layer: liner_relu_stack.4.bias | Size: torch.Size([10]) | Values: tensor([ 0.0378, -0.0203], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#7、打印模型的所有参数\n",
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name,param in model.named_parameters(): #torch.nn.model父类的一个方法，返回一个字典，元组\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values: {param[:2]}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
